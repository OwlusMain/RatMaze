{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RatMazePublic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OwlusMain/RatMaze/blob/main/RatMazePublic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXdYF5ll6fso"
      },
      "source": [
        "import json, random\n",
        "import numpy as np\n",
        "from keras.layers import Activation, Input, Dense, Flatten, Conv2D, MaxPooling2D, Dropout, Reshape, BatchNormalization, Conv2DTranspose\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import SGD , Adam, RMSprop\n",
        "from keras.layers.advanced_activations import PReLU\n",
        "from keras.models import save_model, load_model\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivP6eOaGBtOP"
      },
      "source": [
        "Здесь задаётся маска лабиринта. По умолчанию параметр отвечает за проходимость клетки ($1.0$ - клетка пустая, $0.0$ - клетка заблокирована) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPC_BhhZ6j39"
      },
      "source": [
        "maze = np.array([\n",
        "    [ 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "    [ 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "    [ 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n",
        "    [ 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.],\n",
        "    [ 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.],\n",
        "    [ 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "    [ 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
        "    [ 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.],\n",
        "    [ 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.],\n",
        "    [ 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.]\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVJItMJ3CEKp"
      },
      "source": [
        "Здесь расположены основные константы, которые можно изменять по своему усмотрению"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woOya9kx6n-U"
      },
      "source": [
        "#CONSTANTS\n",
        "\n",
        "#(1) Цвет объектов для отображения\n",
        "colVisited = 0.8\n",
        "#Обратите внимание, что параметр colRat влияет на алгоритм, так как используется для задания координаты мыши в примерах для обучения модели\n",
        "colRat = 0.5\n",
        "colFinish = 0.9\n",
        "\n",
        "#(2) Основной список действий, а также их число. Может быть изменён, если требуется добавить возможность движения по другим направлениям, к примеру, по диагонали\n",
        "leftAct = 0\n",
        "rightAct = 1\n",
        "upAct = 2\n",
        "downAct = 3\n",
        "\n",
        "actionsCnt = 4\n",
        "\n",
        "#(3) Константа, отвечающая за вероятность того, что мышь не последует обученной модели и пойдёт в случайном направлении\n",
        "randEps = 0.1\n",
        "\n",
        "#(4) Константа, использующаяся в уравнении Беллмана для смягчения действий\n",
        "impConst = 0.95\n",
        "\n",
        "#(5) Число действий, которое запоминает мышь при передвижении, а также размер случайной выборки из них для обучения модели\n",
        "ratMemSz = 100\n",
        "ratTrainSamples = 50\n",
        "\n",
        "#(6) Число \"очков\" за попытку совершить различные действия, а также минимально число очков, после которого итерация будет считаться провальной и начнётся заново\n",
        "blockedScore = -1.5\n",
        "cellScore = -0.04\n",
        "visitedScore = -0.25\n",
        "finishScore = 1\n",
        "badEndScore = -0.5 * maze.size\n",
        "\n",
        "#(7) Начальная позиция мыши и финиша, а также размер лабиринта. Обратите внимание, что мышь и лабиринт не должны находиться в заблокированных клетках\n",
        "#Также желательно, чтобы мышь имела возможность добраться до финиша, чтобы задача вообще имела смысл\n",
        "ratPos = [0, 0]\n",
        "finishPos = [maze.shape[0] - 1, maze.shape[1] - 1]\n",
        "mazeRows, mazeCols = maze.shape\n",
        "\n",
        "#(8) Размер основных полносвязных слоёв. Может быть как константным, так и зависеть от, к примеру, размера лабиринта\n",
        "layerSize = 25 #maze.size\n",
        "\n",
        "\n",
        "#(9) Параметры числа эпох и размера батча для обучения модели на одном наборе примеров\n",
        "epochsSize = 8\n",
        "batchSize = 16\n",
        "\n",
        "#(10) Параметры вывода картинки: размер сетки выводимых карт активности (их произведение должно соответствовать числу нейронов layerSize)\n",
        "tensor_w = 5\n",
        "tensor_h = 5\n",
        "\n",
        "#(11) Параметр слоя, для которого формируется карта активности всех нейронов\n",
        "layerForCheck = 3\n",
        "\n",
        "#(12) Параметр нейрона, для которого формируется карта активности в формате [слой, нейрон]\n",
        "curTensor = [1, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PbLXj9GLM-9"
      },
      "source": [
        "Класс __Environment__. Отвечает за среду, в которой агент (мышь) будет перемещаться. Инициализируется с заданной позицией мыши и финиша, проверяет их на корректность, после чего устанавливает состояние и набор свободных клеток.\n",
        "\n",
        "**ResetState(newRatPos)** отвечает за перезагрузку состояния среды. Выставляет мышь в первоначальное положение, сбрасывает массив посещённых клеток, устанавливает текущее количество очков в 0\n",
        "\n",
        "**GetValidActions(cell)** возвращает массив доступных мыши действий в заданной клетке\n",
        "\n",
        "**MakeAction(action)** производит действие, если оно доступно и возвращает информацию о том, было ли действие совершено\n",
        "\n",
        "**CountScore()** на основе произведённого действия считает число полученных очков\n",
        "\n",
        "**BuildEnvState()** строит на основании текущего положения мыши и строения лабиринта одномерный массив envState, формата входа нейронной сети\n",
        "\n",
        "**Act(action)** выполняет действие, считает число полученных очков и новое состояние envState, после чего возвращает эти результаты\n",
        "\n",
        "**CheckStatus()** проверяет условие завершения движения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No_xfJUr9YEY"
      },
      "source": [
        "class Environment(object):\n",
        "    rat = [0, 0]\n",
        "    def __init__(self, rat=ratPos.copy()):\n",
        "        self.finish = finishPos\n",
        "        self.freeCells = []\n",
        "        for i in range(mazeRows):\n",
        "          for j in range(mazeCols):\n",
        "            if maze[i][j] == 1.0 and (i, j) != finishPos:\n",
        "              self.freeCells.append([i, j])\n",
        "        if maze[self.finish[0]][self.finish[1]] == 0.0:\n",
        "            raise Exception(\"Blocked finish!\")\n",
        "        if not self.rat in self.freeCells:\n",
        "            raise Exception(\"Blocked rat!\")\n",
        "        self.ResetState(self.rat)\n",
        "\n",
        "    def ResetState(self, newRatPos):\n",
        "        self.rat = newRatPos\n",
        "        self.curState = 'start'\n",
        "        self.totalScore = 0.0\n",
        "        self.visitedCell = set()\n",
        "\n",
        "    def GetValidActions(self, cell=None):\n",
        "        if cell != None:\n",
        "            self.rat = cell\n",
        "        actions = list(range(actionsCnt))\n",
        "        if self.rat[0] == 0 or maze[self.rat[0] - 1][self.rat[1]] == 0.0:\n",
        "            actions.remove(upAct)\n",
        "        if self.rat[0] == mazeRows - 1 or maze[self.rat[0] + 1][self.rat[1]] == 0.0:\n",
        "            actions.remove(downAct)\n",
        "        if self.rat[1] == 0 or maze[self.rat[0]][self.rat[1] - 1] == 0.0:\n",
        "            actions.remove(leftAct)\n",
        "        if self.rat[1] == mazeCols - 1 or maze[self.rat[0]][self.rat[1] + 1] == 0.0:\n",
        "            actions.remove(rightAct)\n",
        "\n",
        "        return actions\n",
        "\n",
        "    def MakeAction(self, action):\n",
        "        if maze[self.rat[0]][self.rat[1]] == 1.0:\n",
        "            self.visitedCell.add(tuple(self.rat))\n",
        "\n",
        "        validActions = self.GetValidActions()\n",
        "\n",
        "        if action in validActions:\n",
        "            self.curState = 'valid'\n",
        "            if action == leftAct:\n",
        "                 self.rat[1] -= 1\n",
        "            elif action == rightAct:\n",
        "                 self.rat[1] += 1\n",
        "            if action == upAct:\n",
        "                self.rat[0] -= 1\n",
        "            elif action == downAct:\n",
        "                self.rat[0] += 1\n",
        "        else:\n",
        "           self.curState = 'invalid'\n",
        "\n",
        "    def CountScore(self):\n",
        "        if self.rat == finishPos:\n",
        "            return finishScore\n",
        "        if tuple(self.rat) in self.visitedCell:\n",
        "            return visitedScore\n",
        "        if self.curState == 'invalid':\n",
        "            return blockedScore\n",
        "        if self.curState == 'valid':\n",
        "            return cellScore\n",
        "\n",
        "    def BuildEnvState(self):\n",
        "        mazeState = maze.copy()\n",
        "        mazeState[self.rat[0]][self.rat[1]] = colRat\n",
        "        envState = mazeState.reshape((1, -1))\n",
        "        return envState\n",
        "\n",
        "    def Act(self, action):\n",
        "        self.MakeAction(action)\n",
        "        score = self.CountScore()\n",
        "        self.totalScore += score\n",
        "        status = self.CheckStatus()\n",
        "        envState = self.BuildEnvState()\n",
        "        return envState, score, status\n",
        "\n",
        "    def CheckStatus(self):\n",
        "        if self.totalScore < badEndScore:\n",
        "            return 'lose'\n",
        "        if self.rat == self.finish:\n",
        "            return 'win'\n",
        "\n",
        "        return 'continue'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjTI0SreOE2H"
      },
      "source": [
        "**Show(curEnv)** отображает текущее состояние движения типа Environment в графическом виде (отображает текущий лабиринт, мышь, финиш и пройденный мышью путь)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTyE2uOkL8rG"
      },
      "source": [
        "def Show(curEnv):\n",
        "    plt.grid('on')\n",
        "    ax = plt.gca()\n",
        "    ax.set_xticks(np.arange(0.5, mazeRows, 1))\n",
        "    ax.set_yticks(np.arange(0.5, mazeCols, 1))\n",
        "    ax.set_xticklabels([])\n",
        "    ax.set_yticklabels([])\n",
        "    canvas = np.copy(maze)\n",
        "    for curCell in curEnv.visitedCell:\n",
        "        canvas[curCell[0]][curCell[1]] = colVisited\n",
        "    canvas[curEnv.rat[0]][curEnv.rat[1]] = colRat\n",
        "    canvas[finishPos[0]][finishPos[1]] = colFinish\n",
        "    img = plt.imshow(canvas, interpolation='none', cmap='gray')\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAyBCHySOc0Y"
      },
      "source": [
        "**FindPath(model, curEnv, newRatCell, isGenData)** моделирует и выводит путь мыши для текущей модели начиная с newRatCell. (isGenData = True) - функция выводит информацию об активности нейронов и положении мыши на каждой итерации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxK4pTrfNw8-"
      },
      "source": [
        "def FindPath(model, curEnv, newRatCell, isGenData = False):\n",
        "    inp = model.input                              \n",
        "    outputs = [layer.output for layer in model.layers]       \n",
        "    functor = K.function([inp, K.learning_phase()], outputs )\n",
        "    tensorOuts = np.zeros([0, layerSize])\n",
        "    ratPosOuts = []\n",
        "\n",
        "    curEnv.ResetState(newRatCell)\n",
        "    envState = curEnv.BuildEnvState()\n",
        "    while True:\n",
        "        actArr = model.predict(envState)\n",
        "        if(isGenData) :\n",
        "            tensorOuts = np.append(tensorOuts, np.reshape(functor([envState, 1])[layerForCheck][0][:], (1, layerSize)), axis=0)\n",
        "            ratPosOuts.append(curEnv.rat.copy())\n",
        "\n",
        "        action = np.argmax(actArr[0])\n",
        "\n",
        "        newEnvState, reward, game_status = curEnv.Act(action)\n",
        "        envState = newEnvState\n",
        "        if game_status == 'win':\n",
        "            return True, tensorOuts, ratPosOuts\n",
        "        elif game_status == 'lose':\n",
        "            return False, tensorOuts, ratPosOuts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JagPBFv5OniH"
      },
      "source": [
        "**TrainCompleteCheck(model, curEnv)** проверяет условие завершения процесса обучения (в текущем случае мы обучаем до того момента, пока модель не научится находить путь из исходной клетки в финишную, возможно учить, к примеру, находить путь от всех клеток, однако это слишком долгий процесс)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnwNjbe_N0ZM"
      },
      "source": [
        "def TrainCompleteCheck(model, curEnv):\n",
        "    if not curEnv.GetValidActions(ratPos.copy()):\n",
        "        return False\n",
        "    if not FindPath(model, curEnv, ratPos.copy())[0]:\n",
        "        return False\n",
        "    return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPx9isW8PMwQ"
      },
      "source": [
        "Класс **Experience**. отвечает за запоминание последних действий мыши, а также формирование и выдачу выборки для обучения в нужном формате. Инициализируется заданной моделью, а также пустым списком памяти\n",
        "\n",
        "**RememberEpisode(episode)** вносит в память объект episode, содержащий информацию о предыдущем состоянии, совершённом действии, новом состоянии, условии конца, и количестве очков за совершённое действие\n",
        "\n",
        "**Predict(envState)** возвращает результат работы модели на состоянии envState\n",
        "\n",
        "**GetSamplesFromMemory()** возвращает сгенерированную тренировочную выборку. Именно здесь используется уравнение Беллмана для оптимизации действия, совершённого мышью (мы считаем это действие хорошим)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT_z4qwTN26i"
      },
      "source": [
        "class Experience(object):\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.ratMemory = []\n",
        "\n",
        "    def RememberEpisode(self, episode):\n",
        "        self.ratMemory.append(episode)\n",
        "        if len(self.ratMemory) > ratMemSz:\n",
        "            del self.ratMemory[0]\n",
        "\n",
        "    def Predict(self, envState):\n",
        "        return self.model.predict(envState)[0]\n",
        "\n",
        "    def GetSamplesFromMemory(self):\n",
        "        dataSz = min(len(self.ratMemory), ratTrainSamples)\n",
        "        inputs = np.zeros((dataSz, mazeRows * mazeCols))\n",
        "        targets = np.zeros((dataSz, actionsCnt))\n",
        "\n",
        "        for i, j in enumerate(np.random.choice(len(self.ratMemory), dataSz, replace=False)):\n",
        "            envState, action, score, newEnvState, isOver = self.ratMemory[j]\n",
        "            inputs[i] = self.ratMemory[j][0]\n",
        "            targets[i] = self.Predict(self.ratMemory[j][0])\n",
        "            scoreBetter = np.max(self.Predict(self.ratMemory[j][3]))\n",
        "            if isOver:\n",
        "                targets[i, self.ratMemory[j][1]] = self.ratMemory[j][2]\n",
        "            else:\n",
        "                targets[i, self.ratMemory[j][1]] = self.ratMemory[j][2] + impConst * scoreBetter  #Уравнение Беллмана\n",
        "        return inputs, targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUIi_apMSjoP"
      },
      "source": [
        "**ModelTrain(model)** выполняет процесс движения мыши по лабиринту и обучения модели в ходе этого движения, а также проверяет на выполнение условия решения задачи. Основная функция для всей задачи"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuLqkQtqN5xE"
      },
      "source": [
        "def ModelTrain(model):\n",
        "    environment = Environment()\n",
        "\n",
        "    curExp = Experience(model)\n",
        "\n",
        "    cntEpochs = 0\n",
        "\n",
        "    while (True):\n",
        "        loss = 0.0\n",
        "        newRatCell = random.choice(environment.freeCells)\n",
        "        environment.ResetState(newRatCell)\n",
        "        isOver = False\n",
        "\n",
        "        envState = environment.BuildEnvState()\n",
        "\n",
        "        cntEp = 0\n",
        "        while not isOver:\n",
        "            validActions = environment.GetValidActions()\n",
        "            if not validActions: break\n",
        "\n",
        "            if np.random.rand() < randEps:\n",
        "                action = random.choice(validActions)\n",
        "            else:\n",
        "                action = np.argmax(curExp.Predict(envState))\n",
        "\n",
        "            newEnvState, score, status = environment.Act(action)\n",
        "            if status == 'lose':\n",
        "                isOver = True\n",
        "            else :\n",
        "                if status == 'win':\n",
        "                    isOver = True\n",
        "                episode = [envState, action, score, newEnvState, isOver]\n",
        "                curExp.RememberEpisode(episode)\n",
        "                cntEp += 1\n",
        "\n",
        "            inputs, targets = curExp.GetSamplesFromMemory()\n",
        "            model.fit(inputs, targets, epochs=epochsSize,batch_size=batchSize, verbose=0)\n",
        "            loss = model.evaluate(inputs, targets, verbose=0)\n",
        "            envState = newEnvState\n",
        "    \n",
        "        print(\"Current epoch: %d, current loss: %4f, episodes count: %d\" % (cntEpochs, loss, cntEp))\n",
        "        if TrainCompleteCheck(model, environment):\n",
        "            print(\"Finished training!\")\n",
        "            break\n",
        "        cntEpochs += 1\n",
        "\n",
        "    save_model(model, \"ratModel.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhrnItCZS16o"
      },
      "source": [
        "**BuildModel(maze)** строит модель по лабиринту maze. Можно заменять какой угодно моделью, но главное, чтобы она удовлетворяла формату входа и выхода\n",
        "\n",
        "Формат входа: одномерный массив размера числа клеток в лабиринте, где разными числами помечены свободные клетки, заблокированные клетки и клетка с мышью\n",
        "\n",
        "Формат выхода: массив размера числа действий"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-3bKRSiOMWq"
      },
      "source": [
        "def BuildModel(maze):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(layerSize, input_shape=(maze.size,)))\n",
        "    model.add(PReLU())\n",
        "    model.add(Dense(layerSize))\n",
        "    model.add(PReLU())\n",
        "    model.add(Dense(actionsCnt))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lMvH5q_T0-j"
      },
      "source": [
        "Здесь можно проверить Environment на успешное построение и отображение лабиринта"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79PJ0mWZOQXW",
        "outputId": "580edc2e-33df-433b-bf83-05ba608c49fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "curEnv = Environment()\n",
        "Show(curEnv)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1b53de4240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAADrCAYAAACICmHVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAFF0lEQVR4nO3dMWpVaRyH4e8OQkAdCDhwQW5tOpubBbgNN6AbsHcDdwWzAndhFhALy3QWQRFSamVxptAymUmYc5L7xueBW0V+fMS8qM3f1TRNA9h/f9z1A4DrEStEiBUixAoRYoUIsULEg5v84ocPH06Hh4ezPuDg4GA8efJk1s0xxvj+/ft49OjRb71bemttd6m3fvr0aVxcXKwu+9qNYj08PByvX7+e51W/PHv2bLx8+XLWzTHGODk5GS9evPitd0tvre0u9dbj4+Mrv+avwRAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtE3OgG09OnT8fbt29nfcDJycmse3Bfrf7rP6ZarVavxhivxhhjvV5v3717N+sDvn37Nh4/fjzrpt3lNu0utznGGG/evBmnp6eXXjcc0zRd+7Pdbqe5vX//fvZNu8tt2l1uc5qm6Vdjl/bn36wQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArROzFwbSzs7NZN8cYY7PZjPPz88zu0dFR5qiX3d/4YNoYY/bPbrdL7ZaOetl1MA34F2KFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRY2Sur1Wr2z4cPHxbZvPXvzeS64V7sum7Y+lnYbDZjvV7PujmG64aJ3dIFviV3K79nu91uke+B64ZwD4gVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQjXDfdk13XD1s+C64Z7ftFuyV3XDVs/C64bAlcSK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUi9iLWq27O/J/PdrtN7fJT5fdsu93e+vdmL64b1i7wVXZLb63tLvXWvb9uuAS7rbfWdpd6q+uGcA+IFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRDqbd493SW2u7DqbZ3ftNu8ttTpODaXAviBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCNcN92T369ev4/z8fNbNzWYz++bSu+v1evZd1w1nUrpot+TubrebxhizfpbYXHp3Ca4bArdKrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEuG64J7uuG7puOIbrhold1w1dN5wm1w3hXhArRIgVIsQKEWKFCLFChFghQqwQIVaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSIe3PUDoOrLly+zb/748ePKr7luuCe7rhv2rhseHBzMujnGz+uGHz9+dN1wn3ddN+xdN/z8+fPsn+fPn0+T64bQJlaIECtEiBUixAoRYoUIsUKEWCFCrBAhVogQK0SIFSLEChFihQixQoRYIUKsECFWiBArRNzoYNoY42iMcTbzG/4aY1zMvGl3uU27y22OMcbRNE1/XvaF/4x1aavV6nSapmO78++W3lrbvYu3+mswRIgVIvYh1r/tLrZbemtt99bfeuf/ZgWuZx/+ZAWuQawQIVaIECtEiBUi/gFseJy4AOHnUAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dfZ-oZiT_By"
      },
      "source": [
        "Здесь запускается процесс обучения модели. Модель автоматически сохраняется в файл **ratModel.hdf5** после решения задачи"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCEEP5S_OWXC",
        "outputId": "62936c5c-9f1b-400c-c35c-3236a0c8dbd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "model = BuildModel(maze)\n",
        "ModelTrain(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current epoch: 0, current loss: 0.002509, episodes count: 231\n",
            "Current epoch: 1, current loss: 0.120600, episodes count: 210\n",
            "Current epoch: 2, current loss: 0.086647, episodes count: 17\n",
            "Current epoch: 3, current loss: 0.022666, episodes count: 65\n",
            "Current epoch: 4, current loss: 0.027888, episodes count: 26\n",
            "Current epoch: 5, current loss: 0.010317, episodes count: 6\n",
            "Current epoch: 6, current loss: 0.053974, episodes count: 212\n",
            "Finished training!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCPKTVCgUU3-"
      },
      "source": [
        "При необходимости загружаем свою модель с названием **ratModel.hdf5** (в формате .hdf5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1EL9tzFOaVS"
      },
      "source": [
        "model = load_model(\"ratModel.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc4UbtSEUSxp"
      },
      "source": [
        "**normalize_data(tensor_values, maze, isForShow)** нормализует данные по тензорам (минимальное 0, максимальное 1, остальные в промежутке. Данные по заблокированным клеткам и финишу убираются за неимением смысла). isForShow отвечает за преобразование в формат вывода результатов как изображения (в таком случае все значащие величины становятся на отрезке $[0.5, 1]$, а заблокированные и финиш получают значение $0$)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LsomFfxOdxI"
      },
      "source": [
        "def normalize_data(tensor_values, maze, isForShow = False) :\n",
        "    maze2 = 1 - maze\n",
        "    maze[finishPos[0]][finishPos[1]] = 1\n",
        "    tensor_values *= maze2\n",
        "    tensor_values += maze * maze.size * 100\n",
        "    min_val = tensor_values.min()\n",
        "    tensor_values *= maze2\n",
        "    tensor_values -= maze * maze.size * 100\n",
        "    max_val = tensor_values.max()\n",
        "    tensor_values *= maze2\n",
        "    tensor_values -= min_val\n",
        "    tensor_values *= maze2\n",
        "    tensor_values /= max_val - min_val\n",
        "    if isForShow :\n",
        "        tensor_values *= 0.5\n",
        "        tensor_values += 0.5\n",
        "        tensor_values *= maze2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBGEHgPnVOgi"
      },
      "source": [
        "**show_grid(tensor_values)** выводит данные в виде изображения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7p0Gxr6OhRE"
      },
      "source": [
        "def show_grid(tensor_values) :\n",
        "    plt.grid('on')\n",
        "    nrows, ncols =  tensor_values.shape\n",
        "    ax = plt.gca()\n",
        "    ax.set_xticks(np.arange(0.5, nrows, 1))\n",
        "    ax.set_yticks(np.arange(0.5, ncols, 1))\n",
        "    ax.set_xticklabels([])\n",
        "    ax.set_yticklabels([])\n",
        "    img = plt.imshow(tensor_values, cmap='hot')\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWklT0gQVrIV"
      },
      "source": [
        "**check_tensor(model, curEnv, tensor_pos, isForShow)** формирует карту активности на всём лабиринте для заданного нейрона в формате [слой, нейрон]. isForShow регулирует то же, что и в normalize_data выше"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOAZMyKPOiFT"
      },
      "source": [
        "def check_tensor(model, curEnv, tensor_pos, isForShow = False):\n",
        "    inp = model.input                              \n",
        "    outputs = [layer.output for layer in model.layers]       \n",
        "    functor = K.function([inp, K.learning_phase()], outputs )\n",
        "\n",
        "    tensor_values = np.zeros(maze.shape)\n",
        "\n",
        "    for i in range(maze.shape[0]) :\n",
        "        for j in range(maze.shape[1]) :\n",
        "            if(maze[i][j] == 0) :\n",
        "                continue\n",
        "            curEnv.ResetState((i, j))\n",
        "            envstate = curEnv.BuildEnvState()\n",
        "            model.predict(envstate)\n",
        "            tensor_out = functor([envstate, 1])[tensor_pos[0]][0][tensor_pos[1]]\n",
        "            tensor_values[i][j] = tensor_out\n",
        "\n",
        "    normalize_data(tensor_values, 1 - maze.copy(), isForShow)\n",
        "    show_grid(tensor_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFFd3soCWeAl"
      },
      "source": [
        "Выводим карту активности для нужного нейрона curTensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4-5DYI5Okf8",
        "outputId": "05742c79-9889-436c-fd2c-956918c4b897",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "lMaze = Environment()\n",
        "check_tensor(model, lMaze, curTensor, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvo97aIgWjmF"
      },
      "source": [
        "Формируем и сохраняем изображение, содержащее карты активности всех тензоров слоя **layerForCheck**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4FEh7ChOo8E"
      },
      "source": [
        "plt.figure(figsize=(tensor_w, tensor_h))\n",
        "for i in range(tensor_w * tensor_h) :\n",
        "        plt.subplot(tensor_w, tensor_h, i + 1)\n",
        "        check_tensor(model, lMaze, [layerForCheck, i], True)\n",
        "plt.tight_layout()\n",
        "plt.savefig('tensorsMap.png')\n",
        "plt.close()   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vdBVry3XBRw"
      },
      "source": [
        "Проверяем и выводим путь от исходной позиции до финишной, сгенерированный моделью"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Kg0r0XoOquF",
        "outputId": "7bdfb085-c825-430a-b8e4-2c6110ce5af8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "lMaze = Environment()\n",
        "FindPath(model, lMaze, ratPos.copy())\n",
        "Show(lMaze)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1b540f90b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km4iOLarXN6j"
      },
      "source": [
        "**NormalizeDataPath(tensorPath)** отвечает за то же самое, что и normalize_data, только для результатов нейрона на пути"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDmtIU-ecB3r"
      },
      "source": [
        "def NormalizeDataPath(tensorPath) :\n",
        "    minVal = tensorPath.min()\n",
        "    maxVal = tensorPath.max()\n",
        "    tensorPath -= minVal\n",
        "    tensorPath /= maxVal - minVal\n",
        "    return tensorPath"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8vFmdpjcq3w"
      },
      "source": [
        "Формируем и выводим данные об активности всех нейронов слоя layerForCheck для исходного пути в файл **data.csv** формата .csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq_TTAE3X6zU"
      },
      "source": [
        "resFlag, tensorOuts, ratOuts = FindPath(model, lMaze, ratPos.copy(), True)\n",
        "curFile = open(\"data.csv\", \"w\")\n",
        "\n",
        "curFile.write(\"Step, x, y\")\n",
        "for i in range(tensorOuts.shape[1]):\n",
        "    tensorOuts[:, i] = NormalizeDataPath(tensorOuts[:, i])\n",
        "    curFile.write(\",Neuron \" + str(i + 1))\n",
        "curFile.write(\"\\n\")\n",
        "\n",
        "for i in range(tensorOuts.shape[0]):\n",
        "    curFile.write(str(i + 1) + \",\" + str(ratOuts[i][0]) + \",\" + str(ratOuts[i][1]))\n",
        "    for j in range(tensorOuts.shape[1]):\n",
        "        curFile.write(\",\" + str(tensorOuts[i][j]))\n",
        "    curFile.write(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}